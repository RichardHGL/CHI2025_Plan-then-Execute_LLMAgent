{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 complete the NASA-TLX\n",
      "248 complete the whole study\n",
      "{'UP-AE': 61, 'AP-UE': 64, 'AP-AE': 63, 'UP-UE': 60}\n"
     ]
    }
   ],
   "source": [
    "from util import load_user_data, task_order\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "valid_users, tp_data = load_user_data(folder_name=\"../anonymized_data\", reserved_users=None)\n",
    "user2condition = tp_data['user2condition']\n",
    "condition_count = {}\n",
    "for user in valid_users:\n",
    "    tp_condition = user2condition[user]\n",
    "    if tp_condition not in condition_count:\n",
    "        condition_count[tp_condition] = 0\n",
    "    condition_count[tp_condition] += 1\n",
    "print(condition_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict = {}\n",
    "original_quality = {\n",
    "    'test-149': 2,\n",
    "    'test-200': 3,\n",
    "    'test-859': 3,\n",
    "    'test-388': 5,\n",
    "    'test-497': 5,\n",
    "    'test-675': 5\n",
    "}\n",
    "all_conditions = [\"AP-AE\", \"AP-UE\", \"UP-AE\", \"UP-UE\"]\n",
    "condition_dict = {}\n",
    "for condition in all_conditions:\n",
    "    condition_dict[condition] = {}\n",
    "    for task_id in task_order + [\"avg\"]:\n",
    "        condition_dict[condition][task_id] = []\n",
    "\n",
    "plan_quality = tp_data['plan_quality']\n",
    "# calibrated_trust_execution = tp_data[\"calibrated_trust_planning\"]\n",
    "calibrated_trust_execution = tp_data[\"calibrated_trust_execution\"]\n",
    "for task_id in task_order + [\"avg\"]:\n",
    "    variable_dict[task_id] = {\n",
    "        \"condition\": [],\n",
    "        \"planning\": [],\n",
    "        \"execution\": [],\n",
    "        \"calibrated_trust_execution\": []\n",
    "    }\n",
    "\n",
    "for user in valid_users:\n",
    "    tp_condition = user2condition[user]\n",
    "    tp_list = []\n",
    "    for task_id in task_order:\n",
    "        tp_plan_quality = plan_quality[user][task_id]\n",
    "        # skip tasks where plan quality worse than the original quality\n",
    "        if tp_plan_quality < original_quality[task_id]:\n",
    "            continue\n",
    "        tp_ct_e = calibrated_trust_execution[user][task_id]\n",
    "        variable_dict[task_id][\"calibrated_trust_execution\"].append(tp_ct_e)\n",
    "        tp_list.append(tp_ct_e)\n",
    "        condition_dict[tp_condition][task_id].append(tp_ct_e)\n",
    "        variable_dict[task_id][\"condition\"].append(tp_condition)\n",
    "        if tp_condition.startswith(\"AP\"):\n",
    "            variable_dict[task_id][\"planning\"].append(\"automatic\")\n",
    "        else:\n",
    "            variable_dict[task_id][\"planning\"].append(\"user-involved\")\n",
    "        if tp_condition.endswith(\"AE\"):\n",
    "            variable_dict[task_id][\"execution\"].append(\"automatic\")\n",
    "        else:\n",
    "            variable_dict[task_id][\"execution\"].append(\"user-involved\")\n",
    "    # print(user, tp_condition, len(tp_list))\n",
    "    if len(tp_list) == 0:\n",
    "        print(f\"User {user} has no task where plan quality not decrease\")\n",
    "        assert False\n",
    "    else:\n",
    "        variable_dict[\"avg\"][\"calibrated_trust_execution\"].append(np.mean(tp_list))\n",
    "        variable_dict[\"avg\"][\"condition\"].append(tp_condition)\n",
    "        if tp_condition.startswith(\"AP\"):\n",
    "            variable_dict[\"avg\"][\"planning\"].append(\"automatic\")\n",
    "        else:\n",
    "            variable_dict[\"avg\"][\"planning\"].append(\"user-involved\")\n",
    "        if tp_condition.endswith(\"AE\"):\n",
    "            variable_dict[\"avg\"][\"execution\"].append(\"automatic\")\n",
    "        else:\n",
    "            variable_dict[\"avg\"][\"execution\"].append(\"user-involved\")\n",
    "        condition_dict[tp_condition][\"avg\"].append(np.mean(tp_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP-AE\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "63\n",
      "AP-UE\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "UP-AE\n",
      "59\n",
      "55\n",
      "50\n",
      "48\n",
      "53\n",
      "53\n",
      "61\n",
      "UP-UE\n",
      "57\n",
      "55\n",
      "58\n",
      "56\n",
      "54\n",
      "52\n",
      "60\n",
      "test-149 243\n",
      "test-200 237\n",
      "test-859 235\n",
      "test-388 231\n",
      "test-497 234\n",
      "test-675 232\n",
      "avg 248\n"
     ]
    }
   ],
   "source": [
    "for condition in condition_dict:\n",
    "    print(condition)\n",
    "    for key in condition_dict[condition]:\n",
    "        print(len(condition_dict[condition][key]))\n",
    "for task_id in variable_dict:\n",
    "    print(task_id, len(variable_dict[task_id][\"condition\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-149\n",
      "      Source  ddof1  ddof2      F  p-unc     n2\n",
      "0  execution      1    241  0.203  0.653  0.001\n",
      "AP-AE 0.47619047619047616\n",
      "AP-UE 0.4375\n",
      "UP-AE 0.5084745762711864\n",
      "UP-UE 0.49122807017543857\n",
      "0.48 & 0.44 & 0.51 & 0.49 & -\n",
      "-----------------\n",
      "test-200\n",
      "      Source  ddof1  ddof2      F  p-unc     n2\n",
      "0  execution      1    235  1.662  0.199  0.007\n",
      "AP-AE 0.7777777777777778\n",
      "AP-UE 0.828125\n",
      "UP-AE 0.7090909090909091\n",
      "UP-UE 0.8\n",
      "0.78 & 0.83 & 0.71 & 0.80 & -\n",
      "-----------------\n",
      "test-859\n",
      "      Source  ddof1  ddof2      F  p-unc     n2\n",
      "0  execution      1    233  3.078  0.081  0.013\n",
      "AP-AE 0.5079365079365079\n",
      "AP-UE 0.40625\n",
      "UP-AE 0.6\n",
      "UP-UE 0.46551724137931033\n",
      "0.51 & 0.41 & 0.60 & 0.47 & -\n",
      "-----------------\n",
      "test-388\n",
      "      Source  ddof1  ddof2      F  p-unc     n2\n",
      "0  execution      1    229  0.212  0.645  0.001\n",
      "AP-AE 0.9365079365079365\n",
      "AP-UE 0.921875\n",
      "UP-AE 0.875\n",
      "UP-UE 0.8571428571428571\n",
      "0.94 & 0.92 & 0.88 & 0.86 & -\n",
      "-----------------\n",
      "test-497\n",
      "      Source  ddof1  ddof2      F  p-unc   n2\n",
      "0  execution      1    232  0.083  0.774  0.0\n",
      "AP-AE 0.8888888888888888\n",
      "AP-UE 0.921875\n",
      "UP-AE 0.9622641509433962\n",
      "UP-UE 0.9444444444444444\n",
      "0.89 & 0.92 & 0.96 & 0.94 & -\n",
      "-----------------\n",
      "test-675\n",
      "      Source  ddof1  ddof2     F  p-unc     n2\n",
      "0  execution      1    230  1.19  0.276  0.005\n",
      "AP-AE 0.36507936507936506\n",
      "AP-UE 0.375\n",
      "UP-AE 0.2830188679245283\n",
      "UP-UE 0.4230769230769231\n",
      "0.37 & 0.38 & 0.28 & 0.42 & -\n",
      "-----------------\n",
      "avg\n",
      "      Source  ddof1  ddof2      F  p-unc   n2\n",
      "0  execution      1    246  0.002  0.967  0.0\n",
      "AP-AE 0.6587301587301587\n",
      "AP-UE 0.6484375\n",
      "UP-AE 0.6393442622950821\n",
      "UP-UE 0.6522222222222223\n",
      "0.66 & 0.65 & 0.64 & 0.65 & -\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from pingouin import ancova, anova\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "for task_id in task_order + [\"avg\"]:\n",
    "    print(task_id)\n",
    "    df = pd.DataFrame(variable_dict[task_id])\n",
    "    dimension = \"calibrated_trust_execution\"\n",
    "    # aov = anova(dv=dimension, between=['planning', 'execution'], data=df, effsize='n2')\n",
    "    aov = anova(dv=dimension, between=['execution'], data=df, effsize='n2')\n",
    "    # aov = ancova(dv=dimension, covar=[\"Propensity to Trust\", \"Familiarity\", \"llm_expertise\", \"assistant_expertise\"], between='planning', data=df, effsize='n2')\n",
    "    print(aov.round(3))\n",
    "    if aov.to_dict()['p-unc'][0] <= 0.05 / 4:\n",
    "        tukey = pairwise_tukeyhsd(endog=df[dimension], groups=df['execution'], alpha=0.0125)\n",
    "        print(tukey)\n",
    "    tp_str = \"\"\n",
    "    for condition in all_conditions:\n",
    "        print(condition, np.mean(condition_dict[condition][task_id]))\n",
    "        tp_str += \"{:.2f} & \".format(np.mean(condition_dict[condition][task_id]))\n",
    "    if aov.to_dict()['p-unc'][0] <= 0.05 / 4:\n",
    "        tp_str += \"AE < UE\"\n",
    "    else:\n",
    "        tp_str += \"-\"\n",
    "    print(tp_str)\n",
    "    print(\"-\" * 17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
