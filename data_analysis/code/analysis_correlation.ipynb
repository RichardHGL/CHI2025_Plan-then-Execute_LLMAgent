{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 complete the NASA-TLX\n",
      "248 complete the whole study\n",
      "{'AP-AE': 63, 'UP-UE': 60, 'AP-UE': 64, 'UP-AE': 61}\n"
     ]
    }
   ],
   "source": [
    "from util import load_user_data, task_ID_list_to_check\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "valid_users, tp_data = load_user_data(folder_name=\"../anonymized_data\", reserved_users=None)\n",
    "user2condition = tp_data['user2condition']\n",
    "condition_count = {}\n",
    "for user in valid_users:\n",
    "    tp_condition = user2condition[user]\n",
    "    if tp_condition not in condition_count:\n",
    "        condition_count[tp_condition] = 0\n",
    "    condition_count[tp_condition] += 1\n",
    "print(condition_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variable dict\n",
    "variable_dict = {}\n",
    "performance_dv = [\"recall\", \"acc_strict\", \"acc_relaxed\", \"acc_execution\"]\n",
    "trust_dv = [\"Reliability/Competence\", \"Understanding/Predictability\", \"Intention of Developers\", \"Trust in Automation\"]\n",
    "calibrated_trust_dv = [\"calibrated_trust_planning\", \"calibrated_trust_execution\"]\n",
    "nasatlx_variable_names = [\"mental_demand\", \"physical_demand\", \"temporal_demand\", \"performance\", \"effort\", \"frustration\"]\n",
    "covariates = [\"llm_expertise\", \"assistant_expertise\", \"Familiarity\", \"Propensity to Trust\"]\n",
    "\n",
    "user_expertise = tp_data[\"user_expertise\"]\n",
    "plan_quality = tp_data['plan_quality']\n",
    "user_cognitive_load = tp_data['cognitive_load']\n",
    "task_perfromance = tp_data['task_performance']\n",
    "user_TiA_scale = tp_data[\"trust_in_automation\"]\n",
    "risk_perception = tp_data['risk_perception']\n",
    "\n",
    "for dimension in performance_dv:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in trust_dv:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in calibrated_trust_dv:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in nasatlx_variable_names:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in covariates:\n",
    "    variable_dict[dimension] = []\n",
    "variable_dict['risk_perception'] = []\n",
    "variable_dict['plan_quality'] = []\n",
    "variable_dict['trust_planning'] = []\n",
    "variable_dict['trust_execution'] = []\n",
    "user_trust = tp_data['user_trust']\n",
    "trust_mapping = {\n",
    "    \"No\": 0.0,\n",
    "    \"Yes\": 1.0\n",
    "}\n",
    "\n",
    "# correlation based on average on tasks\n",
    "for user in valid_users:\n",
    "    for variable in nasatlx_variable_names:\n",
    "        variable_dict[variable].append(user_cognitive_load[user][variable])\n",
    "    for variable in performance_dv:\n",
    "        variable_dict[variable].append(task_perfromance[user][\"avg\"][variable])\n",
    "    for variable in calibrated_trust_dv:\n",
    "        variable_dict[variable].append(tp_data[variable][user][\"avg\"])\n",
    "    for variable in [\"llm_expertise\", \"assistant_expertise\"]:\n",
    "        variable_dict[variable].append(user_expertise[user][variable])\n",
    "    for variable in trust_dv:\n",
    "        variable_dict[variable].append(user_TiA_scale[user][variable])\n",
    "    for variable in [\"Familiarity\", \"Propensity to Trust\"]:\n",
    "        variable_dict[variable].append(user_TiA_scale[user][variable])\n",
    "    tp_list = []\n",
    "    tp_list_2 = []\n",
    "    tp_list_3 = []\n",
    "    tp_list_4 = []\n",
    "    for task_id in task_ID_list_to_check:\n",
    "        tp_risk = risk_perception[user][task_id]\n",
    "        tp_list.append(tp_risk)\n",
    "        tp_list_2.append(plan_quality[user][task_id])\n",
    "        tp_list_3.append(trust_mapping[user_trust[user][task_id][\"planning\"]])\n",
    "        tp_list_4.append(trust_mapping[user_trust[user][task_id][\"execution\"]])\n",
    "    variable_dict[\"risk_perception\"].append(np.mean(tp_list))\n",
    "    variable_dict[\"plan_quality\"].append(np.mean(tp_list_2))\n",
    "    variable_dict['trust_planning'].append(np.mean(tp_list_3))\n",
    "    variable_dict['trust_execution'].append(np.mean(tp_list_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>acc_strict</th>\n",
       "      <th>acc_relaxed</th>\n",
       "      <th>acc_execution</th>\n",
       "      <th>Reliability/Competence</th>\n",
       "      <th>Understanding/Predictability</th>\n",
       "      <th>Intention of Developers</th>\n",
       "      <th>Trust in Automation</th>\n",
       "      <th>calibrated_trust_planning</th>\n",
       "      <th>calibrated_trust_execution</th>\n",
       "      <th>...</th>\n",
       "      <th>effort</th>\n",
       "      <th>frustration</th>\n",
       "      <th>llm_expertise</th>\n",
       "      <th>assistant_expertise</th>\n",
       "      <th>Familiarity</th>\n",
       "      <th>Propensity to Trust</th>\n",
       "      <th>risk_perception</th>\n",
       "      <th>plan_quality</th>\n",
       "      <th>trust_planning</th>\n",
       "      <th>trust_execution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.569444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recall  acc_strict  acc_relaxed  acc_execution  Reliability/Competence  \\\n",
       "0  0.611111    0.166667     0.333333       0.166667                4.000000   \n",
       "1  0.722222    0.333333     0.666667       0.333333                2.000000   \n",
       "2  0.722222    0.500000     0.500000       0.500000                2.833333   \n",
       "3  0.777778    0.500000     0.666667       0.500000                3.833333   \n",
       "4  0.569444    0.166667     0.500000       0.166667                2.833333   \n",
       "\n",
       "   Understanding/Predictability  Intention of Developers  Trust in Automation  \\\n",
       "0                          4.00                      3.5                  4.0   \n",
       "1                          3.25                      3.0                  2.0   \n",
       "2                          3.00                      3.0                  2.5   \n",
       "3                          3.25                      4.0                  4.0   \n",
       "4                          3.50                      4.0                  3.0   \n",
       "\n",
       "   calibrated_trust_planning  calibrated_trust_execution  ...  effort  \\\n",
       "0                   0.333333                    0.833333  ...       4   \n",
       "1                   0.500000                    0.666667  ...       2   \n",
       "2                   0.500000                    0.666667  ...       3   \n",
       "3                   0.500000                    0.500000  ...       7   \n",
       "4                   0.166667                    0.166667  ...       3   \n",
       "\n",
       "   frustration  llm_expertise  assistant_expertise  Familiarity  \\\n",
       "0           -6              4                    4          2.5   \n",
       "1           -1              3                    4          2.5   \n",
       "2            1              4                    3          4.0   \n",
       "3           -7              3                    4          3.0   \n",
       "4            4              4                    4          2.5   \n",
       "\n",
       "   Propensity to Trust  risk_perception  plan_quality  trust_planning  \\\n",
       "0             3.333333         2.333333      2.833333        1.000000   \n",
       "1             2.666667         2.166667      3.833333        1.000000   \n",
       "2             3.000000         3.166667      3.833333        0.333333   \n",
       "3             3.333333         2.166667      3.833333        1.000000   \n",
       "4             2.666667         1.666667      2.833333        1.000000   \n",
       "\n",
       "   trust_execution  \n",
       "0         0.333333  \n",
       "1         0.666667  \n",
       "2         0.166667  \n",
       "3         1.000000  \n",
       "4         1.000000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(variable_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_pvalue(pvalue, correlation):\n",
    "    tp_str = \"\"\n",
    "    if pvalue < 0.0125:\n",
    "        tp_str += \"& {} &\".format(\"%.3f\"%correlation)\n",
    "        tp_str += \"\\\\textbf{\"\n",
    "        tp_str += \"{}\".format((\"%.3f\"%pvalue)[1:])\n",
    "        tp_str += \"}$^{\\dagger\\dagger}$\"\n",
    "    elif pvalue < 0.05:\n",
    "        tp_str += \"& {} & {}\".format(\"%.3f\"%correlation, (\"%.3f\"%pvalue)[1:])\n",
    "        tp_str += \"$^{\\dagger}$\"\n",
    "    else:\n",
    "        tp_str += \"& {} & {}\".format(\"%.3f\"%correlation, (\"%.3f\"%pvalue)[1:])\n",
    "    return tp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mental_demand & -0.046 & .472& -0.003 & .968& -0.163 &\\textbf{.010}$^{\\dagger\\dagger}$& -0.188 &\\textbf{.003}$^{\\dagger\\dagger}$\\\\\n",
      "physical_demand & 0.314 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.267 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.166 &\\textbf{.009}$^{\\dagger\\dagger}$& 0.219 &\\textbf{.001}$^{\\dagger\\dagger}$\\\\\n",
      "temporal_demand & 0.031 & .623& 0.034 & .593& -0.077 & .225& -0.039 & .542\\\\\n",
      "performance & -0.133 & .036$^{\\dagger}$& -0.154 & .016$^{\\dagger}$& -0.154 & .015$^{\\dagger}$& -0.080 & .209\\\\\n",
      "effort & 0.037 & .562& 0.109 & .087& -0.046 & .470& -0.013 & .839\\\\\n",
      "frustration & -0.249 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.131 & .039$^{\\dagger}$& -0.296 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.348 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n",
      "Reliability/Competence & 0.334 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.245 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.321 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.679 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "Understanding/Predictability & 0.307 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.164 &\\textbf{.010}$^{\\dagger\\dagger}$& 0.208 &\\textbf{.001}$^{\\dagger\\dagger}$& 0.380 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "Intention of Developers & 0.406 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.324 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.362 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.517 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "Trust in Automation & 0.380 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.278 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.356 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.698 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n",
      "recall & -0.075 & .238& -0.077 & .230& -0.003 & .965& -0.013 & .843\\\\\n",
      "acc_strict & 0.037 & .560& -0.014 & .823& 0.110 & .085& 0.018 & .772\\\\\n",
      "acc_relaxed & 0.008 & .906& 0.042 & .515& 0.101 & .112& 0.050 & .435\\\\\n",
      "acc_execution & -0.000 & .995& -0.037 & .567& 0.085 & .184& 0.007 & .911\\\\\n",
      "-----------------\n",
      "calibrated_trust_planning & 0.053 & .404& 0.053 & .402& 0.056 & .378& 0.037 & .566\\\\\n",
      "calibrated_trust_execution & -0.120 & .059& -0.195 &\\textbf{.002}$^{\\dagger\\dagger}$& -0.032 & .621& -0.174 &\\textbf{.006}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n",
      "plan_quality & -0.035 & .587& -0.037 & .560& 0.080 & .211& -0.032 & .611\\\\\n",
      "trust_planning & 0.099 & .119& 0.163 &\\textbf{.010}$^{\\dagger\\dagger}$& 0.233 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.137 & .030$^{\\dagger}$\\\\\n",
      "trust_execution & 0.096 & .130& 0.168 &\\textbf{.008}$^{\\dagger\\dagger}$& 0.091 & .154& 0.292 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "str_dict = {}\n",
    "for dv in nasatlx_variable_names:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in covariates:\n",
    "        correlation, pvalue = spearmanr(variable_dict[cov], variable_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "for dv in trust_dv:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in covariates:\n",
    "        correlation, pvalue = spearmanr(variable_dict[cov], variable_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "\n",
    "for dv in performance_dv:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in covariates:\n",
    "        correlation, pvalue = spearmanr(variable_dict[cov], variable_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "for dv in calibrated_trust_dv:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in covariates:\n",
    "        correlation, pvalue = spearmanr(variable_dict[cov], variable_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "for dv in ['plan_quality', 'trust_planning', 'trust_execution']:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in covariates:\n",
    "        correlation, pvalue = spearmanr(variable_dict[cov], variable_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_perception & -0.187 &\\textbf{.003}$^{\\dagger\\dagger}$& -0.180 &\\textbf{.004}$^{\\dagger\\dagger}$& -0.237 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.363 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n"
     ]
    }
   ],
   "source": [
    "dv = 'risk_perception'\n",
    "str_dict[dv] = \"{} \".format(dv)\n",
    "for cov in covariates:\n",
    "    correlation, pvalue = spearmanr(variable_dict[cov], variable_dict[dv])\n",
    "    # if pvalue < 0.05 / 4:\n",
    "    # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "    str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "str_dict[dv] += \"\\\\\\\\\"\n",
    "print(str_dict[dv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-specific Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"condition\": [],\n",
    "    \"planning\": [],\n",
    "    \"execution\": [],\n",
    "    \"task_id\": [],\n",
    "    \"trust_planning\": [],\n",
    "    \"trust_execution\": [],\n",
    "    \"plan_quality\": [],\n",
    "    \"acc_execution\": [],\n",
    "    \"acc_strict\": [],\n",
    "    \"risk_perception\": [],\n",
    "    \"confidence_planning\": [],\n",
    "    \"confidence_execution\": [],\n",
    "    \"calibrated_trust_planning\": [],\n",
    "    \"calibrated_trust_execution\": []\n",
    "}\n",
    "user_trust = tp_data['user_trust']\n",
    "trust_mapping = {\n",
    "    \"No\": 0.0,\n",
    "    \"Yes\": 1.0\n",
    "}\n",
    "user_confidence = tp_data['confidence']\n",
    "calibrated_trust_planning = tp_data['calibrated_trust_planning']\n",
    "calibrated_trust_execution = tp_data['calibrated_trust_execution']\n",
    "\n",
    "for user in valid_users:\n",
    "    tp_condition = user2condition[user]\n",
    "    planning, execution = tp_condition.split(\"-\")\n",
    "    for task_id in task_ID_list_to_check:\n",
    "        # condition\n",
    "        data_dict[\"condition\"].append(tp_condition)\n",
    "        data_dict[\"planning\"].append(planning)\n",
    "        data_dict[\"execution\"].append(execution)\n",
    "        data_dict[\"task_id\"].append(task_id)\n",
    "\n",
    "        # feedback at planning stage\n",
    "        data_dict[\"plan_quality\"].append(plan_quality[user][task_id])\n",
    "        data_dict[\"risk_perception\"].append(risk_perception[user][task_id])\n",
    "        data_dict[\"trust_planning\"].append(trust_mapping[user_trust[user][task_id]['planning']])\n",
    "        data_dict[\"confidence_planning\"].append(user_confidence[user][task_id]['planning'])\n",
    "        data_dict[\"calibrated_trust_planning\"].append(calibrated_trust_planning[user][task_id])\n",
    "\n",
    "        # feedback at execution stage\n",
    "        for variable in [\"acc_execution\", \"acc_strict\"]:\n",
    "            data_dict[variable].append(task_perfromance[user][task_id][variable])\n",
    "        data_dict[\"trust_execution\"].append(trust_mapping[user_trust[user][task_id]['execution']])\n",
    "        data_dict[\"confidence_execution\"].append(user_confidence[user][task_id]['execution'])\n",
    "        data_dict[\"calibrated_trust_execution\"].append(calibrated_trust_execution[user][task_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for variable in data_dict:\n",
    "#     print(variable, len(data_dict[variable]))\n",
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ghe/opt/anaconda3/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.5.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source       SS    DF        F  p-unc     n2\n",
      "0     condition    0.584     3    0.920   0.43  0.002\n",
      "1  plan_quality   56.149     1  265.231   0.00  0.151\n",
      "2      Residual  313.948  1483      NaN    NaN    NaN\n",
      "condition\n",
      "AP-AE    0.534392\n",
      "AP-UE    0.526042\n",
      "UP-AE    0.467213\n",
      "UP-UE    0.547222\n",
      "Name: acc_execution, dtype: float64\n",
      "-----------------\n",
      "         Source       SS    DF        F  p-unc     n2\n",
      "0     condition    0.986     3    1.631   0.18  0.003\n",
      "1  plan_quality   71.306     1  353.953   0.00  0.192\n",
      "2      Residual  298.759  1483      NaN    NaN    NaN\n",
      "condition\n",
      "AP-AE    0.534392\n",
      "AP-UE    0.463542\n",
      "UP-AE    0.456284\n",
      "UP-UE    0.472222\n",
      "Name: acc_strict, dtype: float64\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from pingouin import ancova, anova\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "for dimension in [\"acc_execution\", \"acc_strict\"]:\n",
    "    # dimension = \"acc_execution\"\n",
    "    # aov = anova(dv=dimension, between=['condition'], data=df, effsize='n2')\n",
    "    aov = ancova(dv=dimension, covar=[\"plan_quality\"], between='condition', data=df, effsize='n2')\n",
    "    print(aov.round(3))\n",
    "    if aov.to_dict()['p-unc'][0] <= 0.05 / 4:\n",
    "        tukey = pairwise_tukeyhsd(endog=df[dimension], groups=df['condition'], alpha=0.0125)\n",
    "        print(tukey)\n",
    "    print(df.groupby('condition').mean()[dimension])\n",
    "    print(\"-\" * 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.groupby(['task_id', 'risk_perception', 'plan_quality'])\n",
    "# print(type(s.count()['acc_execution']))\n",
    "res = pd.concat([s.count()['acc_execution'], s.mean()['acc_execution']], axis=1, ignore_index=True)\n",
    "res.to_csv(\"risk_perception-plan_quality.csv\")\n",
    "# print(df.groupby(['task_id', 'plan_quality']).mean()['acc_execution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1\n",
      "risk_perception               \n",
      "1                485  0.606186\n",
      "2                409  0.484108\n",
      "3                259  0.482625\n",
      "4                227  0.466960\n",
      "5                108  0.453704\n",
      "                0         1\n",
      "plan_quality               \n",
      "1              50  0.060000\n",
      "2             231  0.008658\n",
      "3             482  0.591286\n",
      "4               8  0.500000\n",
      "5             717  0.666667\n"
     ]
    }
   ],
   "source": [
    "s = df.groupby(['risk_perception'])\n",
    "res = pd.concat([s.count()['acc_execution'], s.mean()['acc_execution']], axis=1, ignore_index=True)\n",
    "print(res)\n",
    "\n",
    "s = df.groupby(['plan_quality'])\n",
    "res = pd.concat([s.count()['acc_execution'], s.mean()['acc_execution']], axis=1, ignore_index=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017793587188612098"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(50 * 0.060000 + 231 * 0.008658) / 281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5897956163265305"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.591286 * 482 + 4) / 490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "248 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source       SS    DF         F  p-unc     n2\n",
      "0     condition    1.202     3     3.334  0.019  0.003\n",
      "1  plan_quality  193.756     1  1612.379  0.000  0.519\n",
      "2      Residual  178.209  1483       NaN    NaN    NaN\n",
      "condition\n",
      "AP-AE    0.505291\n",
      "AP-UE    0.494792\n",
      "UP-AE    0.497268\n",
      "UP-UE    0.494444\n",
      "Name: calibrated_trust_planning, dtype: float64\n",
      "-----------------\n",
      "         Source       SS    DF       F  p-unc     n2\n",
      "0     condition    0.136     3   0.206  0.892  0.000\n",
      "1  plan_quality   16.894     1  76.495  0.000  0.049\n",
      "2      Residual  327.513  1483     NaN    NaN    NaN\n",
      "condition\n",
      "AP-AE    0.656085\n",
      "AP-UE    0.645833\n",
      "UP-AE    0.612022\n",
      "UP-UE    0.625000\n",
      "Name: calibrated_trust_execution, dtype: float64\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for dimension in [\"calibrated_trust_planning\", \"calibrated_trust_execution\"]:\n",
    "    # dimension = \"acc_execution\"\n",
    "    # aov = anova(dv=dimension, between=['condition'], data=df, effsize='n2')\n",
    "    aov = ancova(dv=dimension, covar=[\"plan_quality\"], between='condition', data=df, effsize='n2')\n",
    "    print(aov.round(3))\n",
    "    if aov.to_dict()['p-unc'][0] <= 0.05 / 4:\n",
    "        tukey = pairwise_tukeyhsd(endog=df[dimension], groups=df['condition'], alpha=0.0125)\n",
    "        print(tukey)\n",
    "    print(df.groupby('condition').mean()[dimension])\n",
    "    print(\"-\" * 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_execution & 0.400 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.110 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "acc_strict & 0.446 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.096 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n",
      "calibrated_trust_planning & 0.723 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.102 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "calibrated_trust_execution & 0.221 &\\textbf{.000}$^{\\dagger\\dagger}$& 0.000 & .995\\\\\n",
      "-----------------\n",
      "trust_planning & 0.056 & .032$^{\\dagger}$& -0.293 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "trust_execution & 0.258 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.160 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n",
      "confidence_planning & 0.137 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.532 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "confidence_execution & 0.225 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.271 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "str_dict = {}\n",
    "task_performance_variables = [\"acc_execution\", \"acc_strict\"]\n",
    "calibrated_trust_variables = [\"calibrated_trust_planning\", \"calibrated_trust_execution\"]\n",
    "trust_variables = [\"trust_planning\", \"trust_execution\"]\n",
    "confidence_variables = [\"confidence_planning\", \"confidence_execution\"]\n",
    "for dv in task_performance_variables:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in ['plan_quality', 'risk_perception']:\n",
    "        correlation, pvalue = spearmanr(data_dict[cov], data_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "for dv in calibrated_trust_variables:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in ['plan_quality', 'risk_perception']:\n",
    "        correlation, pvalue = spearmanr(data_dict[cov], data_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "for dv in trust_variables:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in ['plan_quality', 'risk_perception']:\n",
    "        correlation, pvalue = spearmanr(data_dict[cov], data_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)\n",
    "\n",
    "for dv in confidence_variables:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in ['plan_quality', 'risk_perception']:\n",
    "        correlation, pvalue = spearmanr(data_dict[cov], data_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan_quality & 1.000 &\\textbf{.000}$^{\\dagger\\dagger}$& -0.141 &\\textbf{.000}$^{\\dagger\\dagger}$\\\\\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for dv in ['plan_quality']:\n",
    "    str_dict[dv] = \"{} \".format(dv)\n",
    "    for cov in ['plan_quality', 'risk_perception']:\n",
    "        correlation, pvalue = spearmanr(data_dict[cov], data_dict[dv])\n",
    "        # if pvalue < 0.05 / 4:\n",
    "        # print(\"Variable {} and variable {} have spearman correlation {:.3f} and pvalue {:.3f}\".format(cov, dv, correlation, pvalue))\n",
    "        str_dict[dv] += wrap_pvalue(pvalue, correlation)\n",
    "    str_dict[dv] += \"\\\\\\\\\"\n",
    "    print(str_dict[dv])\n",
    "print(\"-\" * 17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
