{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 complete the NASA-TLX\n",
      "248 complete the whole study\n",
      "{'UP-UE': 60, 'AP-UE': 64, 'UP-AE': 61, 'AP-AE': 63}\n"
     ]
    }
   ],
   "source": [
    "from util import load_user_data, task_ID_list_to_check\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "valid_users, tp_data = load_user_data(folder_name=\"../anonymized_data\", reserved_users=None)\n",
    "user2condition = tp_data['user2condition']\n",
    "user_planning_actions = tp_data['user_planning_actions']\n",
    "condition_count = {}\n",
    "for user in valid_users:\n",
    "    tp_condition = user2condition[user]\n",
    "    if tp_condition not in condition_count:\n",
    "        condition_count[tp_condition] = 0\n",
    "    condition_count[tp_condition] += 1\n",
    "print(condition_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dict = {}\n",
    "trust_dimensions = [\"Reliability/Competence\", \"Understanding/Predictability\", \n",
    "                    \"Intention of Developers\", \"Trust in Automation\"]\n",
    "covariates_1 = [\"Propensity to Trust\", \"Familiarity\"]\n",
    "performance_dimensions = [\"recall\", \"acc_strict\", \"acc_relaxed\", \"acc_execution\"]\n",
    "covariates = [\"llm_expertise\", \"assistant_expertise\"]\n",
    "all_conditions = [\"AP-AE\", \"AP-UE\", \"UP-AE\", \"UP-UE\"]\n",
    "condition_dict = {}\n",
    "for condition in all_conditions:\n",
    "    condition_dict[condition] = {}\n",
    "    for dimension in trust_dimensions:\n",
    "        condition_dict[condition][dimension] = []\n",
    "    condition_dict[condition][\"calibrated_trust_planning\"] = []\n",
    "    condition_dict[condition][\"calibrated_trust_execution\"] = []\n",
    "    condition_dict[condition][\"RAIR\"] = []\n",
    "    condition_dict[condition][\"RSR\"] = []\n",
    "\n",
    "for dimension in performance_dimensions:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in trust_dimensions:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in covariates_1:\n",
    "    variable_dict[dimension] = []\n",
    "for dimension in covariates:\n",
    "    variable_dict[dimension] = []\n",
    "\n",
    "user_expertise = tp_data[\"user_expertise\"]\n",
    "trust = tp_data[\"trust_in_automation\"]\n",
    "calibrated_trust_planning = tp_data[\"calibrated_trust_planning\"]\n",
    "calibrated_trust_execution = tp_data[\"calibrated_trust_execution\"]\n",
    "variable_dict[\"condition\"] = []\n",
    "variable_dict[\"planning\"] = []\n",
    "variable_dict[\"execution\"] = []\n",
    "variable_dict[\"calibrated_trust_planning\"] = []\n",
    "variable_dict[\"calibrated_trust_execution\"] = []\n",
    "for user in valid_users:\n",
    "    tp_condition = user2condition[user]\n",
    "    if tp_condition not in all_conditions:\n",
    "        # ignore pilot study\n",
    "        continue\n",
    "    variable_dict[\"condition\"].append(tp_condition)\n",
    "    if tp_condition.startswith(\"AP\"):\n",
    "        variable_dict[\"planning\"].append(\"automatic\")\n",
    "    else:\n",
    "        variable_dict[\"planning\"].append(\"user-involved\")\n",
    "    if tp_condition.endswith(\"AE\"):\n",
    "        variable_dict[\"execution\"].append(\"automatic\")\n",
    "    else:\n",
    "        variable_dict[\"execution\"].append(\"user-involved\")\n",
    "    variable_dict[\"calibrated_trust_planning\"].append(calibrated_trust_planning[user][\"avg\"])\n",
    "    condition_dict[tp_condition][\"calibrated_trust_planning\"].append(calibrated_trust_planning[user][\"avg\"])\n",
    "    variable_dict[\"calibrated_trust_execution\"].append(calibrated_trust_execution[user][\"avg\"])\n",
    "    condition_dict[tp_condition][\"calibrated_trust_execution\"].append(calibrated_trust_execution[user][\"avg\"])\n",
    "    for dimension in trust_dimensions:\n",
    "        variable_dict[dimension].append(trust[user][dimension])\n",
    "        condition_dict[tp_condition][dimension].append(trust[user][dimension])\n",
    "    for dimension in [\"Propensity to Trust\", \"Familiarity\"]:\n",
    "        variable_dict[dimension].append(trust[user][dimension])\n",
    "    for dimension in covariates:\n",
    "        variable_dict[dimension].append(user_expertise[user][dimension])\n",
    "    task_performance = tp_data[\"task_performance\"]\n",
    "    for dimension in performance_dimensions:\n",
    "        variable_dict[dimension].append(task_performance[user][\"avg\"][dimension])\n",
    "df = pd.DataFrame(variable_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 248\n",
      "acc_strict 248\n",
      "acc_relaxed 248\n",
      "acc_execution 248\n",
      "Reliability/Competence 248\n",
      "Understanding/Predictability 248\n",
      "Intention of Developers 248\n",
      "Trust in Automation 248\n",
      "Propensity to Trust 248\n",
      "Familiarity 248\n",
      "llm_expertise 248\n",
      "assistant_expertise 248\n",
      "condition 248\n",
      "planning 248\n",
      "execution 248\n",
      "calibrated_trust_planning 248\n",
      "calibrated_trust_execution 248\n"
     ]
    }
   ],
   "source": [
    "for variable in variable_dict:\n",
    "    print(variable, len(variable_dict[variable]))\n",
    "df = pd.DataFrame(variable_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrated_trust_planning, 248\n",
      "M: 0.50, SD: 0.13\n",
      "calibrated_trust_execution, 248\n",
      "M: 0.64, SD: 0.19\n",
      "recall, 248\n",
      "M: 0.77, SD: 0.11\n",
      "acc_strict, 248\n",
      "M: 0.48, SD: 0.17\n",
      "acc_relaxed, 248\n",
      "M: 0.56, SD: 0.17\n",
      "acc_execution, 248\n",
      "M: 0.52, SD: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Performance Overview\n",
    "# dimension = \"calibrated_trust\"\n",
    "for dimension in [\"calibrated_trust_planning\", \"calibrated_trust_execution\"]:\n",
    "    print(\"{}, {}\".format(dimension, len(variable_dict[dimension])))\n",
    "    print(\"M: {:.2f}, SD: {:.2f}\".format(np.mean(variable_dict[dimension]), np.std(variable_dict[dimension])))\n",
    "for dimension in performance_dimensions:\n",
    "    print(\"{}, {}\".format(dimension, len(variable_dict[dimension])))\n",
    "    print(\"M: {:.2f}, SD: {:.2f}\".format(np.mean(variable_dict[dimension]), np.std(variable_dict[dimension])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability/Competence, 248\n",
      "M: 3.49, SD: 0.77\n",
      "Understanding/Predictability, 248\n",
      "M: 3.30, SD: 0.56\n",
      "Intention of Developers, 248\n",
      "M: 3.61, SD: 0.81\n",
      "Trust in Automation, 248\n",
      "M: 3.52, SD: 1.01\n"
     ]
    }
   ],
   "source": [
    "for dimension in trust_dimensions:\n",
    "    print(\"{}, {}\".format(dimension, len(variable_dict[dimension])))\n",
    "    print(\"M: {:.2f}, SD: {:.2f}\".format(np.mean(variable_dict[dimension]), np.std(variable_dict[dimension])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_expertise, 248\n",
      "M: 3.6, SD: 1.0\n",
      "Counter({4: 96, 3: 72, 5: 47, 2: 31, 1: 2})\n",
      "assistant_expertise, 248\n",
      "M: 3.4, SD: 1.1\n",
      "Counter({3: 82, 4: 71, 5: 46, 2: 32, 1: 17})\n",
      "Propensity to Trust, 248\n",
      "M: 3.0, SD: 0.7\n",
      "Counter({3.0: 56, 3.3333333333333335: 55, 2.6666666666666665: 30, 3.6666666666666665: 26, 2.3333333333333335: 23, 2.0: 17, 4.0: 12, 1.6666666666666667: 11, 4.333333333333333: 6, 1.3333333333333333: 5, 4.666666666666667: 4, 5.0: 2, 1.0: 1})\n",
      "Familiarity, 248\n",
      "M: 2.9, SD: 1.2\n",
      "Counter({4.0: 47, 1.0: 37, 2.0: 37, 3.0: 34, 3.5: 27, 2.5: 25, 5.0: 19, 1.5: 12, 4.5: 10})\n"
     ]
    }
   ],
   "source": [
    "# Covariates\n",
    "from collections import Counter\n",
    "for dimension in covariates:\n",
    "    print(\"{}, {}\".format(dimension, len(variable_dict[dimension])))\n",
    "    print(\"M: {:.1f}, SD: {:.1f}\".format(np.mean(variable_dict[dimension]), np.std(variable_dict[dimension])))\n",
    "    print(Counter(variable_dict[dimension]))\n",
    "for dimension in covariates_1:\n",
    "    print(\"{}, {}\".format(dimension, len(variable_dict[dimension])))\n",
    "    print(\"M: {:.1f}, SD: {:.1f}\".format(np.mean(variable_dict[dimension]), np.std(variable_dict[dimension])))\n",
    "    print(Counter(variable_dict[dimension]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
